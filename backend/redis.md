# Redis

## 数据结构

### 基本数据类型

**String(字符串)**

- 可以是字符串、整数或者浮点数
- 用于缓存对象、计数器（INCR）、分布式锁（SET NX EX）、共享session信息

```vbnet
SET key value                 // 设置key的值
GET key                       // 获取key的值
INCR key                      // 将key的值加1
DECR key                      // 将key的值减1
MSET key1 value1 key2 value2  // 批量设置key的值
GETRANGE key start end        // 获取key值的子串
SETEX key seconds value       // 设置key的值并设置过期时间（秒）
```

```vbnet
//分布式锁
SET lock_key unique_value NX EX 10  // 尝试加锁，10秒后过期
// 解锁
if GET lock_key == unique_value then
    DEL lock_key
end if
```

**List（列表）**

- 双向链表，链表上每个节点包含一个字符串
- 用于消息队列（简单版）、时间线（微博、朋友圈）

```vbnet
LPUSH key value          // 从左侧插入元素
RPUSH key value          // 从右侧插入元素
LPOP key                 // 从左侧弹出元素
RPOP key                 // 从右侧弹出元素
LRANGE key start end     // 获取指定范围内的元素
BLPOP key timeout        // 阻塞式从左侧弹出元素，timeout秒后超时
BRPOP key timeout        // 阻塞式从右侧弹出元素，timeout秒后超时
```

**Hash（哈希）**

- 包含键值对的无序哈希表
- 用于小型结构化对象存储，比如用户信息、商品信息

```vbnet
HSET key field value        // 设置哈希表key中field的值
HGET key field              // 获取哈希表key中field的值
HDEL key field              // 删除哈希表key中的field
HGETALL key                 // 获取哈希表key中的所有字段和值
HMSET key field1 value1 ... // 批量设置哈希表key中的字段和值
HMGET key field1 field2 ... // 批量获取哈希表key中的字段值
```

**Set（集合）**

- 字符串的无序不重复的集合
- 用于聚合计算（并集、交集、差集），比如点赞、共同关注

```vbnet
SADD key member            // 向集合key中添加元素member
SREM key member            // 从集合key中删除元素member
SISMEMBER key member       // 判断member是否是集合key的成员
SMEMBERS key               // 获取集合key中的所有成员
SRANDMEMBER key [count]    // 随机获取集合key中的count个成员
SUNION key1 key2 ...       // 获取多个集合的并集
SINTER key1 key2 ...       // 获取多个集合的交集
SDIFF key1 key2 ...        // 获取多个集合的差集
```

**Zset（有序集合）**

- 有序的集合，跳表实现，每个元素都会关联一个分数（score）
- 用于排序场景，如排行榜、延时队列

```vbnet
ZADD key score member                  // 向有序集合key中添加元素member，分数为score
ZINCRBY key score member               // 增加有序集合key中元素member的分数score
ZREM key member                        // 从有序集合key中删除元素member
ZSCORE key member                      // 获取有序集合key中元素member的分数
ZRANGE key start end [WITHSCORES]      // 获取有序集合key中指定范围内的元素，按分数从低到高排序
ZREVRANGE key start end [WITHSCORES]   // 获取有序集合key中指定范围内的元素，按分数从高到低排序
ZRANGEBYSCORE key min max [WITHSCORES] // 获取有序集合key中分数在min和max之间的元素
```

**Bitmaps（位图）**

- 二值状态统计，即0和1
- 用于签到、在线状态

```vbnet
SETBIT key offset value    // 设置位图key中offset位置的值为value
GETBIT key offset          // 获取位图key中offset位置的值
BITCOUNT key [start end]   // 计算位图key中值为1的位数
```

**HyperLogLog（基数统计）**

- 不精确但是节省空间的唯一值计数，内存占用固定为12KB
- 用于统计访客数（UV）、独立IP数

```vbnet
PFADD key element1 element2 ...  // 向HyperLogLog key中添加
PFCOUNT key1 key2 ...            // 获取HyperLogLog key中唯一元素的近似数量
PFMERGE destkey sourcekey1 ...   // 合并多个HyperLogLog到destkey
```

**GEO（地理信息）**

- 存储地理坐标、计算距离、范围查询
- 用于位置服务、附近的人

```vbnet
GEOADD key longitude latitude member        // 向地理空间索引key中添加地理位置
GEOPOS key member1 member2 ...              // 获取地理空间索引key中成员的位置
GEODIST key member1 member2 [unit]          // 计算地理空间索引key中两个成员之间的距离
GEORADIUS key longitude latitude radius unit [WITHCOORD] [WITHDIST] [WITHHASH] [COUNT count] [ASC|DESC] // 查询指定范围内的成员
```

**Stream（流）**

- 消息队列，相比于list可以自动生成唯一ID，支持持久化和消费者组
- 用于日志收集、消息队列（可持久化、可回溯）

```vbnet
XADD key ID field1 value1 [field2 value2 ...]             // 向流key中添加消息，ID可以是*表示自动生成
XREAD [COUNT count] [BLOCK milliseconds] STREAMS key ID   // 读取流key中的消息，ID表示从哪个ID开始读取
XGROUP CREATE key groupname ID                            // 创建消费者组
XREADGROUP GROUP groupname consumer [COUNT count] [BLOCK milliseconds] STREAMS key ID  // 从消费者组中读取消息
XACK key groupname ID1 [ID2 ...]                          // 确认消息已被消费
```

对数据的操作都是原子性的，不存在并发竞争问题

支持事务、持久化、Lua脚本、多种集群方案（主从复制、哨兵、切片集群）、发布订阅、内存淘汰、过期删除

### 底层数据结构

**String（字符串）**

Redis的String看起来只有一种，但是内部会自动选择三种encoding：

- int：当value是整数，底层用整数存储，节省内存
- embstr：字符串长度小于等于39字节，key和value会分配在同一块内存中，减少内存碎片
- raw：字符串长度大于39字节，key和value分配在不同内存中

**List（列表）**

Redis 3.2之后list改为quicklist结构，quicklist是多个listpack（旧的ziplist）的集合，全局由双向链表连接，避免一次性分配过大内存

即紧凑存储+双向链表的结构

**Hash（哈希）**

Hash类型底层有两种实现：

- 小hash用紧凑结构的ziplist存储，连续内存，节省内存开销
- 大hash用哈希表存储，数据量增大时会自动转换，渐进式rehash避免阻塞

**Set（集合）**

Set类型底层有两种实现：

- values小于等于512个且每个value小于等于64字节时，使用intset存储，节省内存
- values较大时升级为使用哈希表存储

**Zset（有序集合）**

Zset类型底层有两种实现：

- 小集合使用listpack紧凑保存member和score
- 大集合或者数据变大时使用跳表+哈希表的结构，跳表按score排序，哈希表用于快速查找member和score

**Bitmap**

Bitmap底层是用String类型存储的，位操作通过位运算实现

**HyperLogLog**

**Stream**

底层使用radix tree（基数树）存储消息ID和消息内容，ID有序，消费者组偏移存储在另一套结构中

### ZSet了解吗

ZSet（有序集合）是一种结合Set的唯一性和排序列表有序性的数据结构，内部有两种实现：

- 默认元素数量小于128且member和score长度都小于64字节时，使用listpack存储：
  - listpack是紧凑、有编码格式的连续内存结构，可以节省空间、减少指针开销
- 基于跳表和哈希表：
  - 哈希表用于查询成员是否存在以及获取成员的分数（score）
  - 跳表用于插入、删除、根据分数排序和范围查询

ZSet的特点是：

- 唯一性：每个元素（member）在集合中是唯一的，如果重复添加会更新分数（score）
- 有序性：元素根据分数从小到大排序
- 支持范围查询：可以通过score或者排名区间查询
- 支持分页：可以直接通过rank做offset/limit

使用ZSet实现排行榜：

- 玩家分数更新加10分：`ZINCRBY game_rank 10 player_A`
- 获取前10名玩家：`ZRANGE game_rank 0 9 WITHSCORES`

使用ZSet实现延迟队列：

- 使用score存储未来执行时间戳：`ZADD delay_queue 1690000000 task1`
- 消费者定期检查任务并执行：`ZRANGEBYSCORE delay_queue -inf current_timestamp`

### 介绍一下listpack

### String是用什么存储的

## 线程模型

### Redis为什么这么快

官方使用基准测试的结果是，单线程的Redis吞吐量可以达到10w/s以上，而多线程的MySQL吞吐量大概在1w/s左右，单线程Redis快的原因在于：

- 内存存储：Redis大部分操作都是在内存中完成的，并且采用了高效的数据结构，内存中的数据读写速度远快于磁盘
- 单线程模型：Redis采用单线程模型可以避免多线程之间的竞争，省去了多线程切换带来的时间和性能上的开销，而且也不会有锁竞争的问题，简化了编程模型，另外Redis性能的瓶颈在于机器的内存或者网络带宽，而不是CPU，因此单线程足以处理大部分请求
- Redis采用了IO多路复用机制处理大量的客户端请求，即一个线程处理多个IO流，避免了线程阻塞等待IO的时间，提高了请求处理能力

### Redis为什么是单线程的

单线程是指接收客户端请求、解析请求、进行数据读写、发送数据给客户端等都是由一个线程完成的

Redis使用单线程的原因：

1. 避免锁竞争：多线程环境下，多个线程同时访问共享数据需要加锁，导致性能下降，而单线程避免了锁竞争问题
2. 对于内存数据库，瓶颈在于机器的网络IO和内存而不是CPU，单线程足以处理大部分请求，实际的瓶颈在于网络IO和内存带宽
3. 单线程具有更简单的编程模型，减少了复杂性和潜在的并发问题
4. Redis不是完全单线程，后台有辅助线程处理AOF重写、内存释放等任务，避免主线程阻塞

> 对于复杂SQL/分析型数据库，CPU消耗较大，多线程更合适，而Redis作为内存键值数据库，单线程足以满足高性能需求，如果想充分发挥CPU多核能力，可以部署多个Redis节点采用分片或者读写分离

> 为什么单线程Redis可以做到数万的QPS <https://mp.weixin.qq.com/s/oeOfsgF-9IOoT5eQt5ieyw>

### Redis哪些地方用到了多线程

Redis的单线程是指接收客户端请求、解析请求、进行数据读写等操作、发送数据给客户端这个过程是由一个线程（主线程）来完成的

但是Redis程序本身不是单线程运行的，Redis在启动的时候，除了负责执行命令的主线程，还会启动后台线程：

- bio_close_file：延迟关闭文件描述符/关闭临时文件等操作（如RDB/AOF结束后的文件关闭、释放等）
- bio_aof_fsync：用于异步执行AOF的fsync操作，将AOF缓冲区的数据写入磁盘，避免主线程阻塞
- bio_lazy_free：用于惰性释放大对象/大key占用的内存，当执行UNLINK、FLUSHDB ASYNC等，该线程负责真正释放内存
- 另外默认会启动3个IO线程来分担Redis网络IO的压力，因为随着硬件的发展，网络IO成为Redis的瓶颈，IO线程负责网络读写和请求解析/序列化，主线程专注于命令执行
- 还会创建一些子进程用于持久化（RDB快照、AOF重写）、集群节点间数据迁移等操作

### Redis怎么实现IO多路复用

Redis使用单线程执行命令，但是需要同时处理多个客户端的连接，如果每个连接都阻塞等待IO操作，会导致性能下降，IO多路复用技术可以让单个线程同时处理多个IO流，避免阻塞等待，提高请求处理能力

Redis的IO多路复用模型：

- 一个socket客户端与服务端连接时，会对应生成一个套接字描述符（一种文件描述符），每一个socket网络连接其实都对应一个文件描述符
- 多个客户端与服务端连接时，Redis的多路复用程序会把这些文件描述符注册监听队列中，当客户端有读写操作时，多路复用程序会将命令封装成一个事件，并绑定到对应的文件描述符上
- 文件事件处理器使用IO多路复用模块同时监控多个文件描述符的读写情况，当某个文件描述符有读写事件时，文件事件处理器就会回调文件描述符绑定的事件处理器处理命令操作

例如：以Redis的IO多路复用程序epoll函数为例，多个客户端连接到服务端时，Redis会将客户端的文件描述符注册到epoll的监听队列中，当某个客户端发送命令时，epoll会检测到该文件描述符有读事件，然后调用对应的事件处理器读取命令并执行

整个文件事件处理器是在单线程上运行的，但是通过IO多路复用模块的引入，实现了对多个文件描述符的同时监控和处理，避免了阻塞等待

## 事务

### redis如何实现原子性和事务

Redis执行命令的时候是单线程的，所以不会存在多线程并发的安全问题，因此单个命令的执行是原子性的

但是如果需要执行多个命令作为一个整体操作，要保证多个命令的原子性有以下方法：

- 事务（MULTI/EXEC）
  - 将多个命令放在MULTI和EXEC之间，Redis会将这些命令打包成一个事务，保证这些命令要么全部执行成功，要么全部不执行
- Lua脚本（EVAL）
  - 将多个命令写在一个Lua脚本中，Redis会将这个脚本作为一个整体执行，保证脚本中的命令要么全部执行成功，要么全部不执行

### 多实例的Redis如何避免数据竞争

Redis的并发数据竞争是指多个客户端同时对同一个key发去读写操作时，由于业务逻辑不是原子执行而导致结果错误

Redis单线程模型本身不会发生内部数据竞争，因为Redis在同一时刻只能执行一条命令，但是客户端之间操作流程不完整或非原子事务时，就会产生逻辑级别的竞争问题

Redis事务不一定能避免并发的数据竞争，因为Redis事务只能保证事务内部的命令是原子执行的，不能保证事务内部命令执行前的数据不会被其他客户端修改，即事务之间没有隔离性，如：

- 客户端A和B都有事务：

  ```sql
  MULTI
  GET counter
  SET counter xxx
  EXEC
  ```

- 执行顺序不一定是：

  ```sql
  A: GET → SET → EXEC
  B: GET → SET → EXEC
  且B的GET在A的SET之后发生
  ```

- 真正的顺序可能是：

  ```sql
  A: MULTI
  A: GET                  # 读到 counter=100（只是排队记录，还未执行）

  B: MULTI
  B: GET                  # 也读到 counter=100（同样只是排队，还未执行）

  A: SET counter=101      # 排队
  A: EXEC                 # 执行队列，正式写入 counter=101

  B: SET counter=101      # 排队
  B: EXEC                 # 也执行队列，重新写入 counter=101
  ```

因此可以使用以下方法避免数据竞争：

- 使用分布式锁（SET NX EX）
  - 在操作共享数据前，先获取一个分布式锁，确保同一时刻只有一个客户端可以操作该数据，操作完成后释放锁
  - `SET NX EX`命令可以原子性地设置锁，并设置过期时间，避免死锁，`NX`表示只有当key不存在时才设置成功，`EX`表示设置过期时间，例如：

    ```vbnet
    SET lock_key unique_value NX EX 10  // 尝试加锁，10秒后过期
    // 解锁
    if GET lock_key == unique_value then
        DEL lock_key
    end if
    ```

- 使用Lua脚本（EVAL）
  - 将多个命令写在一个Lua脚本中，Redis会将这个脚本作为一个整体执行，保证脚本中的命令要么全部执行成功，要么全部不执行，避免了多个客户端同时操作同一个key导致的数据竞争问题
  - 即单个Lua脚本执行时是原子性的，其他客户端的命令会被阻塞等待脚本执行完成

## 日志

### 日志持久化

AOF（Append Only File）：

- 每次执行一个命令都追加写入到一个磁盘文件中（先执行再写日志），恢复数据时逐一执行命令
- 服务器宕机可能导致执行成功但日志写入失败，从而数据丢失
- 写日志也是主线程执行的，会阻塞后续操作
- 日志是先追加到缓冲区，然后再写入AOF文件，有三种策略：
  - Always（每次操作都把缓冲区日志写到硬盘）
  - Everysec（每秒把缓冲区写到硬盘）
  - No（操作系统决定何时把缓冲区写到硬盘）
- AOF重写机制：
  - 为了避免AOF文件持续增大，当大小超过阈值会读取所有键值对，每个用一条命令记录到新的AOF文件然后替换（后台子进程完成），重写缓冲区和AOF缓冲区一起用

RDB快照（Redis Database File）

- 将某一时刻的内存数据（实际数据而不是执行的命令），以二进制的方式写入磁盘，数据恢复效率比AOF快
- save命令（主线程）和bgsave命令（子进程，写时复制Copy-On-Write，COW）

混合持久化

- 开启之后，AOF重写日志时，fork的子进程会先将主线程共享的内存数据以RDB方式写入AOF文件，然后主线程的操作记录在重写缓冲区，以AOF形式写入AOF文件
- 混合持久化的AOF文件前面是RDB格式的全量数据，后面是AOF格式的增量数据

> AOF是最安全的持久化方式，但是文件体积较大、恢复速度慢；RDB恢复速度快、文件体积小，但是可能丢失数据。混合持久化结合了两者的优点

## 内存淘汰和过期删除

内存淘汰是指当Redis内存使用达到配置的maxmemory限制时，会根据配置的淘汰策略删除部分数据，释放内存空间，内存淘汰的策略有：

1. noeviction：（默认）不淘汰数据，返回报错
2. volatile-random：随机淘汰设置过期时间的数据
3. volatile-ttl：优先淘汰设置过期时间中快要过期的数据
4. volatile-lru：淘汰设置过期时间中最久未使用的数据
5. volatile-lfr：淘汰设置过期时间中最少使用的数据
6. allkeys-random：随机淘汰任意数据
7. allkeys-lru：淘汰最久没使用的数据
8. allkeys-lfu：淘汰最少使用的数据

过期删除是指对于设置了过期时间的key，Redis会在key过期后将其删除，释放内存，过期删除的策略是惰性删除+定期删除：

- 对key设置了过期时间后，会把key存储到一个过期词典中，读取key时会判断是否过期
- 不主动删除过期key，访问到的时候如果过期则删除，定期（默认10s）也会取出一定量的key，删除其中过期的key
- RDB文件生成的时候，会对key进行过期检查，过期的key不会保存到RDB文件中，主服务器加载的时候也不会加载过期的key
- AOF文件中如果key过期删除会追加删除的命令，AOF重写的时候会检查过期的key不会写到新的AOF文件中

## 集群

### 运行模式

- 单机模式（Standalone）
  - 只有一个Redis实例，没有高可用，简单性能好但是容易单点故障
- 主从复制（Master-Slave Replication）
  - 主服务器负责读写操作，从服务器负责读取主服务器的数据进行同步
  - 没有自动故障转移功能，主服务器宕机需要手动提升从服务器为主服务器
- 哨兵模式（Sentinel）
  - 有哨兵监控主从服务器状态，提供自动故障转移功能，自动选举新的主服务器
- 切片集群（Cluster）
  - 数据分布在多个节点上，提高读写性能，支持自动故障转移
  - 一个切片集群有16384个哈希槽，每个键值对会映射到一个槽，创建集群的时候会均匀分配槽位，或者手动分配

### 主从之间增量和全量同步

使用Redis主从复制时，主服务器会将数据同步到从服务器，分为全量同步和增量同步两种方式

**全量同步**发生在：

- 初次同步：当一个从服务器首次连接到主服务器时，会进行一次全量同步
- 从服务器数据丢失：如果从服务器数据由于某种原因丢失，会请求进行全量同步
- 主服务器数据变化较大：如果从服务器的数据长时间没有与主服务器同步，导致数据差异较大，可能会触发全量同步

主从的第一次全量同步可以分为三个阶段：

1. 建立链接、协商同步
   - 从服务器发送`SYNC`命令给主服务器，主服务器检查是否需要进行全量同步
2. 主服务器同步数据到从服务器
   - 主服务器生成RDB快照文件，并将其发送给从服务器，从服务器接收并加载RDB文件，完成数据同步
3. 主服务器发送新的写操作给从服务器
   - 快照文件传输过程中，主服务器会将新的写操作记录在replication backlog buffer，RDB文件传输完成后，主服务器会将buffer中的命令发送给从服务器，从服务器执行命令确保数据一致性

> **replication backlog buffer**是Redis主从复制机制中的一个环形缓冲区，用于记录主节点最近写入的命令，便于从节点进行增量同步，默认大小是1M（可通过参数调整），缓冲区写满之后会覆盖旧数据

**增量同步**允许从服务器从断点处继续同步，而不是每次都进行全量同步，增量同步基于`PSYNC`命令实现，使用了`run ID`和`offset`机制：

- 从服务器在与主服务器建立连接时，会发送`PSYNC`命令，并携带上次同步的`run ID`和`offset`：`PSYNC <run ID> <offset>`
- 主服务器根据`run ID`和`offset`判断是否可以进行增量同步：
  - `offset`标记的是buffer的同步进度，主服务器的`offset`标记当前buffer的写入位置，从服务器的`offset`标记上次同步的位置
  - 如果`run ID`匹配且`offset`在主服务器的replication backlog buffer范围内，主服务器会发送从上次断点处开始的增量数据给从服务器
  - 如果不匹配，主服务器会回复`-ERR`，要求从服务器进行全量同步
- 主服务器

### CAP理论

CAP理论是指在分布式系统中，不可能同时满足一致性（Consistency）、可用性（Availability）和分区容错性（Partition Tolerance）这三个特性：

- 一致性（Consistency）：所有节点在同一时间看到的数据是一致的
- 可用性（Availability）：系统在任何时候都能响应客户端的请求，不会因为某个节点故障导致无法提供服务
- 分区容错性（Partition Tolerance）：即使网络分区导致节点之间的通信失败，系统能够继续运行

### Redis是CAP模型吗

Redis可以被看作是一个AP模型的分布式系统：

- 主从节点的数据复制是异步的，从节点的数据可能短暂滞后，因此是最终一致性，而不是强一致性
- 满足可用性和分区容错性，即使某个主节点不可用，其他主节点或者从节点仍然可以提供服务，网络分区时系统仍然可以继续运行

> 对于主从复制模式，主节点提供写操作，从节点提供读操作，主节点故障时可以手动提升从节点为主节点或者通过哨兵来选举主节点，来保证CAP中的可用性

ETCD是典型的CP模型：写入操作需要在大多数节点上达成一致才能成功，保证强一致性，但是在网络分区时可能会牺牲可用性

### 哨兵的原理

哨兵（Sentinel）是Redis提供的一种高可用解决方案，用于监控Redis主从节点的状态，并在主节点发生故障时自动进行故障转移，提升从节点为新的主节点

主节点发生故障后，哨兵会通过以下步骤进行故障转移：

1. 故障节点主观下线
   - 哨兵集群的每个哨兵节点会定期向redis集群的所有节点发送PING心跳包，如果在一定时间内没有收到响应，则认为该节点主观下线
2. 故障节点客观下线
   - 当一个节点被多数（quorum数量）哨兵节点主观下线后，该节点就会被认为是客观下线
   - 如果是从节点下线，则直接标记为下线，如果是主节点下线，则进入故障转移流程
3. 哨兵集群选举leader
   - 为了防止多个哨兵节点同时进行故障转移，哨兵集群会选举出一个leader节点，只有leader节点才有权限进行故障转移
4. Leader决定新的主节点
   - 哨兵的leader节点会从所有可用的从节点中选择一个作为新的主节点
   - 新的主节点选择会先过滤故障节点，然后优先选择优先级slave-priority最大的节点，其次是数据最完整的节点，最后是ID最小的节点

### 切片集群了解吗

切片集群（Cluster）是Redis提供的一种分布式解决方案，用于将数据分布在多个节点上，以此来降低系统对单个节点的依赖，从而提高Redis服务的读写性能

切片集群方案没有使用一致性哈希，而是采用固定数量的哈希槽（Hash Slots）机制，来处理数据和节点之间的映射关系：切片集群有16384个哈希槽（Hash Slots），每个键值对会映射到一个哈希槽：

- 根据键值对的key，按照CRC16算法计算出一个16位的哈希值（0~65535）
- 然后将这个哈希值对16384取模，得到该key对应的哈希槽编号

16384个哈希槽会均匀分布到多个节点上，分布的方案有两种：

- 自动分配：创建集群时，Redis会自动将16384个哈希槽均匀分配到所有节点上
  - 例如三个节点时，哈希槽会被分配为：0-5460, 5461-10922, 10923-16383
- 手动分配：管理员可以通过命令手动将哈希槽分配到不同节点上

使用16384个Slot（数量是65535的四分之一），可以更均匀地分布数据，尽量避免某些节点存储过多数据，这样在节点数量变化时，可以通过迁移Slot来重新平衡数据分布，并且只需要对迁移部分的slot进行rehash，而不是对所有数据进行rehash，降低了扩容缩容的成本

### 切片模式的数据倾斜

> <https://segmentfault.com/a/1190000046839476>

数据倾斜分为：

- 存储倾斜：某些Slot上存储的Key数量过多，导致某些节点存储压力过大
- 请求倾斜：某些热点Key被频繁访问，导致某些节点的请求压力过大

导致数据倾斜的原因与解决方案：

- Bigkey导致存储倾斜
  - BigKey对应的Value过大（String值很大或者集合元素多），导致slot所在的节点数据量过大，内存资源紧张
  - 解决方案：避免将过多的数据保存在一个键值对中，如果是集合类型可以将大对象拆分成多个小对象存储
- Slot分配不均导致存储倾斜
  - 手动分配Slot时，如果分配不均匀，可能导致某些节点存储过多数据
  - 解决方案：使用自动分配Slot功能，或者在手动分配时，确保各节点分配的Slot数量均衡
- Hash Tag导致请求倾斜
  - Hash Tag是Redis Cluster中的一种机制：如果key中包含`{}`则只对`{}`中的内容计算hash，这样可以将多个Key映射到同一个Slot上，方便对相关数据进行同分片的操作
  - 解决方案：合理设计`{}`的内容，让访问相关联的key落在同一slot，但是避免过多热点key集中在同一个slot
- 数据访问倾斜
  - 热点数据被存在某个Slot上，导致该Slot所在节点请求压力过大，即使重新分配Slot也无法解决问题
  - 解决方案：可以通过监控工具发现热点key，考虑将热点key进行重新分配，或者使用读写分离，将热点key的读请求分散到多个从节点上

对于存储倾斜，以上是设计层面的解决方案，也可以在运维层面可以通过Rebalance来解决：当检测到某个节点的负载过高或增加节点时，可以通过`redis-cli --cluster rebalance <IP>:<PORT>`命令，Redis会自动将部分Slot从高负载节点迁移到低负载节点，来平衡各节点的负载

## 场景问题

### Redis和本地缓存的区别

- 本地缓存：数据存储在应用程序的内存中，访问速度非常快，适用于单实例应用
  - 优点：访问速度快、实现简单、无网络开销
  - 缺点：数据不共享、内存有限、无法持久化
- Redis缓存：数据存储在独立的Redis服务器中，适用于分布式应用
  - 优点：数据共享、内存大、支持持久化、多种数据结构
  - 缺点：网络开销、访问速度相对较慢

### 单节点Redis和MySQL的并发量

单节点Redis的并发量通常可以达到每秒几十万到上百万次请求，具体取决于硬件配置、网络条件和命令类型

- 如果缓存命中，4核8g的内存配置，Redis可以支撑10w的QPS

单节点MySQL的并发量通常在每秒几千到几万次请求，具体取决于硬件配置、查询复杂度和优化程度

- 如果缓存没有命中，4核8g的内存配置，MySQL可以支撑5000的QPS

### 缓存模型

缓存模型（Cache Model）是使用缓存来提升系统读性能、降低数据库或下游服务压力的一套架构思想和策略集合，Redis是其中常用的缓存组件之一

| 模型                           | 读操作                                        | 写操作                        | 优点                     | 缺点                                   | 适用场景                                 |
| ------------------------------ | --------------------------------------------- | ----------------------------- | ------------------------ | -------------------------------------- | ---------------------------------------- |
| Cache Aside（旁路缓存）        | 先读缓存，缓存 miss 再读 DB，并写回缓存       | 更新数据库后**删除缓存**      | 简单、常用、行业标准     | 删除缓存到读缓存之间可能出现短暂不一致 | 很多互联网系统（例如商品详情、用户信息） |
| Read/Write Through（读写穿透） | 应用不直接访问数据库，写时同时写入 DB & Cache | 由 Cache 层负责同步更新数据库 | 一致性更好               | 实现复杂、吞吐下降                     | 强一致系统                               |
| Write Behind（异步批量写）     | 读走缓存                                      | 写入缓存后异步批量刷写 DB     | 写性能极高，减少 DB 压力 | 存在丢失风险、一致性差                 | 日志、指标统计、大数据写入               |

### Redis和MySQL双写一致性

> <https://cloud.tencent.com/developer/article/2311288>

在使用MySQL和Redis做读写的时候吗，会遇到双写一致性的问题：Redis和MySQL的数据可能在写入或更新过程中不同步，导致缓存脏数据或读到旧数据，对于这个问题有几种解决方案：

**先更新MySQL数据再删除Redis缓存**

- 应用更新数据时，先写入MySQL，再删除Redis缓存，MySQL的数据是最新的，但是可能会有短暂的时间窗口导致读到旧缓存数据
- 如果Redis缓存删除失败会导致缓存和数据库不一致，可以通过延迟双删除、消息重试，binlog补偿解决，如MySQL binlog通过mq推送事件异步更新/删除Redis缓存，保证最终一致性
- 适合读多写少的场景，适合大部分业务场景

**先删除Redis缓存再更新MySQL数据**

- 应用更新数据时，先删除Redis缓存，再写入MySQL，下次访问时缓存不存在会读取MySQL并写回Redis
- 在并发场景下可能会读到旧缓存数据，即Redis缓存被删除后，另一个请求读取了MySQL旧数据并写回Redis，即脏缓存重建，可以加上分布式锁或延迟双删机制解决，即写入MySQL后等待一段时间（如50ms）再删除一次Redis缓存，确保旧缓存被清除
- 适合写多读少、同一个Key短时间频繁更新的场景，对于热点数据更新频繁的场景，期望是尽量不要命中旧缓存，删除缓存之后让缓存空窗等待最终值

为什么是删除缓存而不是更新缓存？

- 有些缓存的值是通过复杂计算之后再放到Redis里的，如果不是热点数据可能长时间不会被访问到，所以每次都更新缓存的成本较高
- 其次是用到懒加载的方式，只有在缓存被用到且不存在时才会去加载数据并放到缓存中

### Redis有哪些适用场景

- 缓存数据：最常见的用途就是作为缓存系统，将频繁访问的数据存储在Redis中，减少数据库访问压力，提高响应速度
- 排行榜：Redis的有序集合（ZSet）非常适合实现排行榜功能，可以高效地进行排名和分数更新
- 分布式锁：利用Redis的原子操作，可以实现分布式锁，保证多个进程或服务之间的互斥访问
- 计数器：Redis的INCR命令可以高效地实现计数器功能，如网站访问量统计、点赞数等
- 消息队列：Redis可以用作轻量级的消息队列，使用stream或list数据结构实现消息的发布和订阅

### 分布式锁怎么实现

分布式锁是为了在多个进程、节点之间协调对共享资源的访问，确保同一时间只有一个客户端能够持有锁访问该资源，一个可靠的分布式锁需要满足：

1. 互斥性：同一时间只有一个客户端能持有锁
2. 死锁避免：锁应该有过期时间，防止持有锁的客户端崩溃导致锁无法释放
3. 可重入性（可选）：同一客户端可以多次获取同一把锁
4. 高可用性：服务宕机也不会导致锁丢失

redis可以作为一个共享存储系统被多个客户端共享，也可以用来实现分布式锁：

- Redis单机实现
  - 使用SET命令的NX和EX参数来实现分布式锁
  - 例如：`SET lock_key unique_value NX EX 10`，`NX`表示只有当lock_key不存在时才设置锁，`EX`设置锁的过期时间为10秒，防止死锁，当unique_value不存在插入成功，表示加锁成功
  - 释放锁时，需要检查unique_value是否匹配，防止误删其他客户端的锁（锁过期后被其他客户端获取）

  ```lua
  if redis.call("get", KEYS[1]) == ARGV[1] then  // 这里的ARGV[1]是unique_value
      return redis.call("del", KEYS[1])
  else
      return 0
  end
  ```

- 多节点Redis实现
  - 使用Redlock算法，在多个独立的Redis节点上获取锁，只有在大多数节点上成功获取锁才算成功，释放锁时也需要在大多数节点上删除锁
  - 这样可以提高分布式锁的可靠性，防止单点故障导致锁丢失

### 大key的问题

Redis的大key是指某个key对应的value值占用的内存较大，导致Redis的性能下降、内存不足、主从同步延迟等问题，通常认为字符串类型的key对应的value值超过1M，或者集合类型的元素数量超过1w个就算是大key（标准不固定）

大key会导致的问题：

- 内存占用过高：大key会占用大量内存，可能导致Redis实例内存不足，触发内存淘汰机制
- 性能下降：操作大key时需要更多的CPU和IO资源，可能导致Redis响应变慢，影响整体性能
- 阻塞其他操作：大key的操作可能是阻塞性的，导致其他命令无法及时处理
- 网络传输延迟：大key在主从复制或集群迁移时需要传输大量数据，可能导致网络延迟和阻塞
- 主从同步延迟：大key的传输时间较长，可能导致主从节点之间的网络传输延迟，影响数据一致性
- 数据倾斜：在Redis集群中，大key可能导致某个节点存储过多数据，影响负载均衡

如何找到大key：

- 使用redis-cli的--bigkeys选项，可以扫描Redis实例中的所有key，并统计各类型key的大小，找出最大的key，可视化工具有RedisInsight、rdbtools/redis-rdb-cli（分析RDB文件）等

  ```bash
  redis-cli --bigkeys
  ```

- 使用MEMORY USAGE命令，可以查看某个key占用的内存大小，编写脚本结合SCAN命令遍历所有key，找出占用内存较大的key

  ```bash
  # SCAN cursor [MATCH pattern] [COUNT count]
  SCAN 0 MATCH user:* COUNT 100 # 从游标0开始获取100个以user:开头的key

  MEMORY USAGE key_name
  ```

如何解决大key问题：

- 对大key进行拆分：将大key拆分成多个小key存储，例如将一个大的列表拆分成多个小列表，确保每个key的成员数量在合理范围内
- 对大key进行清理：定期检查和清理不必要的大key，释放内存资源
- 清理过期数据：为大key设置合理的TTL，确保过期数据能够及时删除，对于集合类型，持续写入时可以定期删除过期成员

### 热key的问题

Redis的热key是指在一段时间内被频繁访问的key，通常是指某个key在短时间内的访问次数远高于其他key，例如：

- QPS集中特定的key：Redis实例的总QPS为1w，而其中某个key的QPS达到7k以上
- 带宽使用率集中在特定的key：对一个拥有上千个成员且总大小为1MB的Hash key每秒发送大量的HGETALL操作请求
- CPU使用时间占比集中在特定的key：对一个拥有数万个成员的key（ZSet类型）每秒发送大量的ZRANGE操作请求

热key会导致以下问题：

- 性能瓶颈：热key的频繁访问会导致流量集中在少数几个节点，单节点压力不均，整体性能瓶颈在热点key节点
- 数据倾斜：在Redis集群中，热key落在的slot所在的节点会有过多请求，导致节点请求量不均匀
- 缓存击穿：热key过期后，可能会有大量请求直接访问数据库，导致数据库压力过大
- 锁竞争：多个客户端同时访问热key时，可能会导致分布式锁的竞争，阻塞时间过长，影响性能
- 网络拥塞：热key的频繁访问会导致网络带宽被热key占用，影响其他请求的响应时间，如果同时又是大key，网络传输压力更大

如何找到热key：

- 使用`OBJECT idletime/refcount`命令获取key的空闲时间或引用计数，找出最近被频繁访问的key

  ```bash
  OBJECT idletime <key>    # 闲置时间越小，越可能是热点
  OBJECT refcount <key>    # 引用次数高说明被频繁交互
  ```

- 使用`redis-cli --hotkeys`可以扫描Redis实例中的所有key，并统计各key的访问频率，找出热key

  ```bash
  redis-cli --hotkeys
  ```

- 使用`INFO commandstats`命令查看各命令的调用次数和耗时，结合业务逻辑分析可能的热key

  ```bash
  INFO commandstats
  ```

- 业务监控采样：在应用层面进行监控采样埋点，记录访问的key和频率，然后可以通过Prometheus+Grafana进行可视化分析找出热key

如何解决热key问题：

- 在Redis集群架构中对热key复制并迁移到其他节点的分片，来解决单个数据分片的热key压力过大问题
  - 例如原来的key是`product:1001:detail`，把这同一个数据写到多个key，落在不同的节点，写数据时也同步更新所有副本（读多写少），访问的时候随机请求一个key

  ```
  product:1001:detail:0   → Node A
  product:1001:detail:1   → Node B
  product:1001:detail:2   → Node C
  product:1001:detail:3   → Node D
  ```

- 使用读写分离架构，将热key的读请求分散到多个从节点上，减轻主节点压力，但是也会增加集群复杂度

### 缓存雪崩、击穿、穿透

缓存雪崩

- 大量缓存数据同一时间过期，此时如果有大量请求，会导致数据库压力过大
- 解决方案：缓存实效时间打散、设置缓存不过期

缓存击穿

- 热点数据过期，导致大量请求直接访问数据库
- 解决方案：互斥锁保证及时重建缓存、设置热点数据不过期

缓存穿透

- 请求的数据不在缓存中，也不在数据库中（数据被误删）
- 解决方案：限制非法请求、设置空返回值或默认值、使用布隆过滤器快速判断数据是否存在

### 布隆过滤器

### 管道

是为了解决多个命令执行时的网络等待，把多个命令整合到一起发送到服务器端处理之后统一返回给客户端

### 事务回滚

redis事务不支持回滚，即不保证事务的原子性

### 内存优化

Redis 内存优化主要从几方面入手：

1. 减少key数量（合并key）
   - 每个key的RedisObject元数据开销大概50字节，因此减少key数量可以节省大量内存
   - 可以把多个key合并到一个Hash/List/Set/Zset中，避免元数据开销过大
2. 减少key/field/value字符串长度
   - key和field尽量短一些
   - value如果是字符串，尽量使用短字符串或者数字
3. 使用小型encoding（listpack、intset、embstr）
   - 尽量使用小型encoding的数据结构，减少内存开销
4. 避免大对象，大Hash，大ZSet
5. 给缓存设置TTL，及时删除过期数据
6. 使用value压缩（snappy、zstd）
7. 合理maxmemory+LRU/LFU剔除
8. 关闭或优化AOF
9. 使用Redis 7的active defrag与jemalloc调优

核心思想就是：减少metadata+减少高层结构+减少大字段
