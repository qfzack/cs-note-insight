## 自我介绍

面试官你好，我叫xxx，现在是在XX做软件开发工程师，我们部门是做云基础设施产品的研发，我们组是负责部门的devops工作

我在这边的主要工作是：

- 开发devops平台的后端功能
  - 负责其中一个是研发效能系统，是衡量代码贡献值的指标，这个主要是开发后端服务来收集我们的GitHub的commit数据，jira上项目管理的工单数据，以及第三方系统分析的的数据，然后进行清洗、聚合和展示，为部门提供一个研发效能度量的体系
  - 负责的另一个服务是提供我们的产品研发生命周期中的关键数据，因为我们最终交付的release产物是一个大的制品，*产品研发的过程中需要持续来构建这个最终制品，并做一些相关的测试，这个服务就是提供这个制品里的关键信息*，需要知道当前产品release的状态、开发阶段、使用到哪些代码仓库，分别是用到哪些分支或者tag，包含哪些文件如docker镜像，镜像的版本是什么，还有helm chart文件、RPM包、压缩文件等，这些信息都是由这个服务从CI pipeline的打包构建开始，来收集、整理并以REST API的方式提供给产品研发流程中进行使用
  - 另外，会使用go开发代码质量门禁检查的服务，这和CI pipeline做的事情有些类似，我们通过go的服务来执行的，比如检查PR是否有多个commit、标题是否符合规范，这和CI pipeline做的事情有些类型
  - 对于我们所有微服务都是部署在一个openshift私有云集群上，并负责devops平台所有微服务的容器化构建、自动化部署和保证服务稳定

- 参与了CICD体系的建设，包括Jenkins CI和Github Actions
  - 我们的Jenkins pipeline主要负责一些制品的构建，比如docker镜像、helm chart文件、RPM包等，以及运行一些测试用例、代码规范检查、安全扫描等

- 此外会负责一些产品开发过程需要做的事情，比如基于suse的sles15来控制我们使用的suse rpm包的版本，构建所有镜像基础容器，还有使用blackduck创建产品的软件材料清单（SBOM）

我比较熟悉golang微服务的开发、服务容器化、CICD流程和体系以及K8s的相关使用，有自己基于CRD开发一个redis operator，是使用kubebuilder搭建的，并打包成Helm chart提供快速部署

---

## 研发效能系统

Github APP

- 除了执行webhook，还可以执行PR审批、代码扫描，都是通过一个service来注册github app实现的
- 除了执行PR检查，还会将github事件分发到其他的服务

Metrics

- 产品、代码仓库、团队、个人总当量的值和变化趋势
- 产品、代码仓库、团队、个人总commit的值、变化趋势
- 产品当前正在进行的工单（feat、bug）以及开发状态（进入到开发状态多久了、点数、哪个产品线的），bug的优先级、当前状态、平均多久处理完
- epic的点数，commit总数，当量总值，当前进度
- 单独展示异常或重要的状态：bug长时间没有修复、优先级较高的bug

### 技术亮点

重试和幂等机制

- 要做到不丢失和不重复消费
- 接收到event之后放到MQ或者数据库中，后台worker进行异步处理（实际没有保存payload实现异步）
- 用commit的sha和repo作为数据库ID，来保证重复请求的幂等性，已经存在则跳过

混合存储

- postgres存储结构化的核心数据，mongo存储原始的非结构化的数据
- json等半结构化数据适合mongo，如果后续业务需要可以重新解析或者补全处理
- 清洗后的字段可以支持业务，方便做查询和统计

schema演进/版本管理

- 用golang-migrate管理postgres schema变更
- mongo通过json schema validation + 中间件做schema校验，避免数据不一致

批量写入/异步化

- 高并发场景下，不要逐条写DB，可以用MQ做缓冲，然后再批量写入
- 这样瞬时量很大也可以平滑处理

增量采集精准去重

- 全量同步效率低，增量同步易丢失数据
- 在Postgres创建一张表记录最后采集的ID/timestamp
- 用mongo change stream监听实时变更（代替轮循）
- 布隆过滤器内存去重

增量采集和近实时处理

- 实现分钟级甚至秒级的数据延迟（尤其是github事件）
- 使用MQ监听jira和github的webhook，利用流处理引擎（flink、spark streaming、kafka streams）进行实时清洗、转换和初步聚合，集合Lambda或Kappa结构，确保数据的一致性和可追溯性

复杂数据关系的关联和图谱构建

- 不仅仅是展示基本指标，而是构建实体（任务、提交、PR、人员、团队、代码库、产品）之间的关联网络
- 使用图数据库存储jira、PR/commit、开发者之间的关系（比如谁review了谁的PR，某个issue关联了哪些commit/PR），使用图算法获取更全面的数据

智能异常标注

- 需要人工识别数据波动是否异常
- 使用postgres窗口函数自动标记离群点，使用颜色阈值高亮异常点，来自动发现效能问题
